{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9816afd-b5a5-4723-be61-0aaf6ee60ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, numpy as np, pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce51d49-f81d-4ffe-a4fa-b29ad134f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', \n",
    "                   'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see',\n",
    "                   'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', \n",
    "                   'right', 'line', 'even', 'also', 'may', 'take', 'come'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548eedb-c729-4bbe-90b6-ead0c8c67471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c4282-698b-4564-9ee0-04852927c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the dataset\n",
    "df= pd.read_csv('C:/Users/GAURAV/Desktop/tripadvisor_hotel_reviews.csv')\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c570b85-3267-41b9-83d1-bfa76f2da233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chekcing the number of reviews we have\n",
    "print(\"Number of reviews - \",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49ca8f-c66c-4303-9811-7942166f6c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing 9k data for fast response\n",
    "df_words= df[0:9000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9a76d-40b4-4ddf-a74d-aa92067f01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a19aa-1073-4c1e-95d9-b443bb54200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df_words.Review.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059bd4e-f3db-43e1-8049-ee2ebcc9e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e17d0c-86e1-479f-a726-4a77b8606b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    #nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ee6d1-bc37-43de-8a74-e567b33ec27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af730511-7bc9-4521-bc65-3e3819f41fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = process_words(data_words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9110f-2bbd-42e6-a15c-9416a1781bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=100,\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33117c6-2c28-480c-946d-38db050fe43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                #sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "                new_row = pd.Series([int(topic_num), round(prop_topic, 4), topic_keywords])\n",
    "                sent_topics_df = pd.concat([sent_topics_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c44d71-d3f9-4d8a-b7e5-817d171a7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a5226-ef9c-4b82-851d-0dc980b9f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Wordcloud of Top N words in each topic\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba25032-cfe5-4605-a90b-90db73c6d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Define colors for low and high frequency\n",
    "def color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "    frequency = word_freq[word]\n",
    "    norm_frequency = frequency / max_frequency  # Normalize by max frequency\n",
    "    r = int(255 * (1 - norm_frequency))  # Red decreases with frequency\n",
    "    g = int(255 * norm_frequency)  # Green increases with frequency\n",
    "    return f'rgba({r}, {g}, 0, 1)'  # Full opacity\n",
    "\n",
    "# Prepare the combined word frequencies\n",
    "word_freq = {}\n",
    "for topic in lda_model.show_topics(formatted=False):\n",
    "    for word, freq in topic[1]:\n",
    "        word_freq[word] = word_freq.get(word, 0) + freq  # Sum frequencies for the same word\n",
    "\n",
    "max_frequency = max(word_freq.values())  # Get the maximum frequency for normalization\n",
    "\n",
    "# Create WordCloud object\n",
    "cloud = WordCloud(stopwords=STOPWORDS,\n",
    "                  background_color='white',\n",
    "                  width=400,\n",
    "                  height=250,\n",
    "                  max_words=500,  # Adjust the number of words if needed\n",
    "                  color_func=color_func,  # Use the custom color function\n",
    "                   prefer_horizontal=1.0,  # Increase horizontal preference\n",
    "                  collocations=False,  # Disable collocations to reduce spacing\n",
    "                  margin=1)  # Reduce margin between words\n",
    "\n",
    "# Generate the word cloud from combined frequencies\n",
    "cloud.generate_from_frequencies(word_freq, max_font_size=300)\n",
    "\n",
    "# Plot the word cloud\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cloud, interpolation='bilinear')\n",
    "plt.axis('off')  # Turn off the axis\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e141d-f0fe-4ef0-8a89-a3ae603c3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "data_flat = [w for w_list in data_ready for w in w_list]\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16,10), sharey=True, dpi=160)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=cols[i])\n",
    "    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
    "    ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
    "    ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout(w_pad=2)    \n",
    "fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509662a-8be2-4ced-b0d8-6ae98c13a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Extract topics from LDA model\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "data_flat = [w for w_list in data_ready for w in w_list]\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "# Prepare the output data\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i, weight, counter[word]])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])\n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10), sharey=True, dpi=160)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "\n",
    "# Custom topic names (replace these with your actual topic names)\n",
    "topic_names = ['Topic A', 'Topic B', 'Topic C', 'Topic D']\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    # Bar for Word Count\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id == i, :], \n",
    "           color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    \n",
    "    # Twin axis for Weights\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id == i, :], \n",
    "                color=cols[i], width=0.2, label='Weights', alpha=0.7)\n",
    "    \n",
    "    # Axis labels and titles\n",
    "    ax.set_ylabel('Word Count', color=cols[i])\n",
    "    ax_twin.set_ylim(0, 0.030)  \n",
    "    ax.set_ylim(0, 3500)\n",
    "    ax.set_title(topic_names[i], color=cols[i], fontsize=16)  # Custom topic titles\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    \n",
    "    # Improve x-axis labels\n",
    "    ax.set_xticklabels(df.loc[df.topic_id == i, 'word'], rotation=30, horizontalalignment='right')\n",
    "    \n",
    "    # Legends\n",
    "    ax.legend(loc='upper left')\n",
    "    ax_twin.legend(loc='upper right')\n",
    "\n",
    "# Final adjustments for the figure\n",
    "fig.tight_layout(w_pad=2)    \n",
    "fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dba5f4-fab4-4496-81aa-d454ac8dd9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary=lda_model.id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ddc87-cad9-4ad1-a228-26ec10934903",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyLDAvis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
